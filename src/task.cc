# include <xkomp/xkomp.h>
# include <xkomp/kmp.h>

# include <xkrt/logger/logger.h>

# include <assert.h>

// task args
typedef struct  task_args_t
{
    task_t * task;
    size_t task_size;
    // followed by the kmp task
}               task_args_t;

// see llvm impl
const size_t
round_up_to_val(size_t size, size_t val)
{
    if (size & (val - 1))
    {
        size &= ~(val - 1);
        if (size <= SIZE_MAX - val)
            size += val;
    }
    return size;
}

static inline kmp_task_t *
ktask_from_task(task_t * task)
{
    task_args_t * args = (task_args_t *) TASK_ARGS(task);
    assert(args);

    kmp_task_t * ktask = (kmp_task_t *) (args + 1);
    assert(ktask);

    return ktask;
}

static inline task_t *
task_from_ktask(kmp_task_t * ktask)
{
    assert(ktask);

    task_args_t * args = (task_args_t *) (((char *) ktask) - sizeof(task_args_t));
    assert(args);
    assert((void *)(args + 1) == (void *) ktask);
    assert(args->task);
    // assert(TASK_ARGS(args->task) == (void *) args);

    return args->task;
}

// called from a non-device thread
static inline void
body_omp_task(task_t * task)
{
    constexpr int32_t gtid = 0;
    kmp_task_t * ktask = ktask_from_task(task);
    assert(ktask);

    ktask->routine(gtid, ktask);
}

# pragma message(TODO "Remove this hack, and pass the task as a parameter of LLVM's offload library - which requires to patch the CodeGen to get the task")
# if XKOMP_HACK_TARGET_CALL
_Thread_local task_t                            * XKOMP_CURRENT_TASK                        = NULL;
_Thread_local stream_t                     * XKOMP_CURRENT_STREAM                      = NULL;
_Thread_local stream_instruction_t         * XKOMP_CURRENT_STREAM_INSTRUCTION          = NULL;
_Thread_local stream_instruction_counter_t   XKOMP_CURRENT_STREAM_INSTRUCTION_COUNTER  = 0;
# endif /* XKOMP_HACK_TARGET_CALL */

extern "C"
{
    task_t *
    xkomp_current_task(void)
    {
        return XKOMP_CURRENT_TASK;
    }

    stream_t *
    xkomp_current_stream(void)
    {
        return XKOMP_CURRENT_STREAM;
    }

    stream_instruction_t *
    xkomp_current_stream_instruction(void)
    {
        return XKOMP_CURRENT_STREAM_INSTRUCTION;
    }

    stream_instruction_counter_t
    xkomp_current_stream_instruction_counter(void)
    {
        return XKOMP_CURRENT_STREAM_INSTRUCTION_COUNTER;
    }
};

// called from a device thread, progressing instructions
static inline void
body_omp_task_target(
    stream_t * stream,
    stream_instruction_t * instr,
    stream_instruction_counter_t idx
) {
    task_t * task = (task_t *) instr->kern.vargs;
    assert(task);

    constexpr int32_t gtid = 0;
    kmp_task_t * ktask = ktask_from_task(task);
    assert(ktask);

    # if XKOMP_HACK_TARGET_CALL
    thread_t * thread = thread_t::get_tls();
    assert(thread);
    assert(thread->current_task != task);

    XKOMP_CURRENT_TASK = task;
    XKOMP_CURRENT_STREAM = stream;
    XKOMP_CURRENT_STREAM_INSTRUCTION = instr;
    XKOMP_CURRENT_STREAM_INSTRUCTION_COUNTER = idx;

    # endif /* XKOMP_HACK_TARGET_CALL */

    // run the routine, that is a function generated by LLVM that fallbacks to libomptarget
    ktask->routine(gtid, ktask);
}

inline static kmp_task *
task_alloc(
    ident_t * loc_ref,
    kmp_int32 gtid,
    kmp_tasking_flags_t flags,
    size_t sizeof_kmp_task_t,
    size_t sizeof_shareds,
    kmp_routine_entry_t task_entry,
    kmp_int32 ndeps,
    kmp_int32 device_id
) {
    // there is a '1' offset between omp device id and xkaapi device id
    static_assert(HOST_DEVICE_GLOBAL_ID == 0);
    device_global_id_t device_global_id = (device_id == -1) ? HOST_DEVICE_GLOBAL_ID : (device_id + 1);

    assert(ndeps <= TASK_MAX_ACCESSES);

    thread_t * thread = thread_t::get_tls();
    assert(thread);

    xkomp_t * xkomp = xkomp_get();
    assert(xkomp);

    task_flag_bitfield_t xkflags  = TASK_FLAG_ZERO;
    if (ndeps)
        xkflags |= TASK_FLAG_DEPENDENT;
    if (device_global_id != HOST_DEVICE_GLOBAL_ID)
    {
        xkflags |= TASK_FLAG_DEVICE;        // execute on a device thread
        xkflags |= TASK_FLAG_DETACHABLE;    // a device task may submit instructions
    }
    const size_t task_size = task_compute_size(xkflags, ndeps);

    // see llvm impl
    const size_t args_size      = sizeof(task_args_t) + sizeof_kmp_task_t;
    const size_t total_size     = task_size + args_size;
    const size_t shareds_offset = round_up_to_val(total_size, sizeof(void *));
    assert(shareds_offset >= total_size);
    assert(shareds_offset % sizeof(void *) == 0);

    task_t * task = thread->allocate_task(shareds_offset + sizeof_shareds);
    assert(task);
    new (task) task_t(xkomp->task_format, xkflags);

    task_args_t * args = (task_args_t *) TASK_ARGS(task, task_size);
    assert(args);
    args->task      = task;
    args->task_size = task_size;

    if (xkflags & TASK_FLAG_DEVICE)
    {
        task_dev_info_t * dev = TASK_DEV_INFO(task);
        new (dev) task_dev_info_t(device_global_id, UNSPECIFIED_TASK_ACCESS);

        assert(xkflags & TASK_FLAG_DETACHABLE);
        task_det_info_t * det = TASK_DET_INFO(task);
        new (det) task_det_info_t();
    }

    kmp_task_t * ktask = (kmp_task_t *) (args + 1);
    assert(ktask);

    ktask->shareds = (sizeof_shareds > 0) ? ((char *) task) + shareds_offset : NULL;
    ktask->routine = task_entry;
    ktask->part_id = 0;

    # ifndef NDEBUG
    snprintf(task->label, sizeof(task->label), "omp-task");
    # endif /* NDEBUG */

    return ktask;
}

extern "C"
kmp_task_t *
__kmpc_omp_task_alloc_with_deps(
    ident_t * loc_ref,
    kmp_int32 gtid,
    kmp_tasking_flags_t flags,
    size_t sizeof_kmp_task_t,
    size_t sizeof_shareds,
    kmp_routine_entry_t task_entry,
    kmp_int32 ndeps
) {
    return task_alloc(loc_ref, gtid, flags, sizeof_kmp_task_t, sizeof_shareds, task_entry, ndeps, -1);
}

extern "C"
kmp_task_t *
__kmpc_omp_target_task_alloc_with_deps(
    ident_t * loc_ref,
    kmp_int32 gtid,
    kmp_tasking_flags_t flags,
    size_t sizeof_kmp_task_t,
    size_t sizeof_shareds,
    kmp_routine_entry_t task_entry,
    kmp_int64 device_id,
    kmp_int32 ndeps
) {
    // target task is untied defined in the specification
    # define TASK_UNTIED    0
    # define TASK_TIED      1
    flags.tiedness = TASK_UNTIED;

    return task_alloc(loc_ref, gtid, flags, sizeof_kmp_task_t, sizeof_shareds, task_entry, ndeps, device_id);
}

extern "C"
kmp_task_t *
__kmpc_omp_target_task_alloc(
    ident_t * loc_ref,
    kmp_int32 gtid,
    kmp_tasking_flags_t flags,
    size_t sizeof_kmp_task_t,
    size_t sizeof_shareds,
    kmp_routine_entry_t task_entry,
    kmp_int64 device_id
) {
    LOGGER_WARN("You are most likely not using the patched version of LLVM/clang for XKOMP, execution may fail.");
    constexpr kmp_int32 ndeps = 0;
    return task_alloc(loc_ref, gtid, flags, sizeof_kmp_task_t, sizeof_shareds, task_entry, ndeps, device_id);
}

extern "C"
kmp_task_t *
__kmpc_omp_task_alloc(
    ident_t * loc_ref,
    kmp_int32 gtid,
    kmp_tasking_flags_t flags,
    size_t sizeof_kmp_task_t,
    size_t sizeof_shareds,
    kmp_routine_entry_t task_entry
) {
    LOGGER_WARN("You are most likely not using the patched version of LLVM/clang for XKOMP, execution may fail.");
    constexpr kmp_int32 ndeps = 0;
    constexpr kmp_int32 device_id = -1;
    return task_alloc(loc_ref, gtid, flags, sizeof_kmp_task_t, sizeof_shareds, task_entry, ndeps, device_id);
}

extern "C"
kmp_int32
__kmpc_omp_task(
    ident_t * loc_ref,
    kmp_int32 gtid,
    kmp_task_t * ktask
) {
    task_t * task = task_from_ktask(ktask);

    xkomp_t * xkomp = xkomp_get();
    assert(xkomp);

    // TODO: im not sure why we need all that mess, see MPC and LLVM impl to
    // figure out what's going on with untied tasks
    /* LLVM calls both
     *  '__kmpc_omp_task' and '__kmpc_omp_task_with_deps'
     * if a task is untied and has dependences.
     * In such case, the task was already commit in the previous call to
     * '__kmpc_omp_task_with_deps'
     */
    if (task->state.value == TASK_STATE_READY)
    {
        body_omp_task(task);
        return 1;
    }
    xkomp->runtime.task_commit(task);

    return 0;
}

/*!
@ingroup TASKING
@param loc_ref location of the original task directive
@param gtid Global Thread ID of encountering thread
@param ktask task thunk allocated by __kmp_omp_task_alloc() for the ''new
task''
@param ndeps Number of depend items with possible aliasing
@param dep_list List of depend items with possible aliasing
@param ndeps_noalias Number of depend items with no aliasing
@param noalias_dep_list List of depend items with no aliasing

@return Returns either TASK_CURRENT_NOT_QUEUED if the current task was not
suspended and queued, or TASK_CURRENT_QUEUED if it was suspended and queued

Schedule a non-thread-switchable task with dependences for execution
*/
extern "C"
kmp_int32
__kmpc_omp_task_with_deps(
    ident_t * loc_ref,
    kmp_int32 gtid,
    kmp_task_t * ktask,
    kmp_int32 ndeps,
    kmp_depend_info_t * dep_list,
    kmp_int32 ndeps_noalias,
    kmp_depend_info_t * noalias_dep_list
) {
    assert(ndeps <= TASK_MAX_ACCESSES);
    task_t * task = task_from_ktask(ktask);

    if (ndeps)
    {
        task_dep_info_t * dep = TASK_DEP_INFO(task);
        new (dep) task_dep_info_t(ndeps);

        // set accesses
        access_t * accesses = TASK_ACCESSES(task);
        for (int i = 0; i < ndeps ; ++i)
        {
            const void * ptr = (const void *) dep_list[i].base_addr;
            if (ptr)
            {
                access_mode_t           mode        = ACCESS_MODE_V;
                access_concurrency_t    concurrency = ACCESS_CONCURRENCY_SEQUENTIAL;
                access_scope_t          scope       = ACCESS_SCOPE_NONUNIFIED;

                if (dep_list[i].flags.in)
                {
                    mode |= ACCESS_MODE_R;
                }
                if (dep_list[i].flags.out)
                {
                    mode |= ACCESS_MODE_W;
                }
                if (dep_list[i].flags.mtx)
                {
                    mode |= ACCESS_MODE_W;
                    concurrency = ACCESS_CONCURRENCY_COMMUTATIVE;
                }
                if (dep_list[i].flags.set)
                {
                    mode |= ACCESS_MODE_W;
                    concurrency = ACCESS_CONCURRENCY_CONCURRENT;
                }
                if (dep_list[i].flags.all)
                {
                    LOGGER_FATAL("Not implemented");
                }

                new (accesses + i) access_t(task, ptr, mode, concurrency, scope);
            }
        }

        // process deps
        thread_t * thread = thread_t::get_tls();
        assert(thread);
        thread->resolve(task, accesses, ndeps);
    }

    xkomp->runtime.task_commit(task);

    # define TASK_CURRENT_NOT_QUEUED    0
    # define TASK_CURRENT_QUEUED        1
    return TASK_CURRENT_QUEUED;
}

extern "C"
kmp_int32
__kmpc_omp_taskwait(
    ident_t * loc_ref,
    kmp_int32 gtid
) {
    xkomp_t * xkomp = xkomp_get();
    xkomp->runtime.task_wait();
    return 0;
}

void
xkomp_task_register_format(xkomp_t * xkomp)
{
    task_format_t format;
    memset(format.f, 0, sizeof(format.f));
    format.f[TASK_FORMAT_TARGET_HOST] = (task_format_func_t) body_omp_task;
    format.f[TASK_FORMAT_TARGET_CUDA] = (task_format_func_t) body_omp_task_target;
    snprintf(format.label, sizeof(format.label), "omp-task");
    xkomp->task_format = task_format_create(&(xkomp->runtime.formats.list), &format);
}
